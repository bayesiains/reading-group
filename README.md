# Bayesiains Reading Group

*Time and place*: 2-3pm on Thursdays, IF 5.02

## Topics/papers

### Variational Inference

- Blei tutorial (https://arxiv.org/abs/1601.00670 ?)
- [Local Reparameterization Trick](https://arxiv.org/abs/1506.02557). Excl. variational dropout stuff. More detailed treatment in related [PhD thesis (PDF)](https://www.dropbox.com/s/v6ua3d9yt44vgb3/cover_and_thesis.pdf?raw=1).
- [Multiplicative Normalizing Flows for Variational Bayesian Neural Networks](https://arxiv.org/abs/1703.01961)
- K-FAC:
  - [Optimizing Neural Networks with Kronecker-factored Approximate Curvature](https://arxiv.org/abs/1503.05671)
  - [Noisy Natural Gradient as Variational Inference](https://arxiv.org/abs/1712.02390)
- [Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam](https://arxiv.org/abs/1806.04854)
- [
The Description Length of Deep Learning Models](https://arxiv.org/abs/1802.07044). Information theoretic analysis of variational approximations for neural nets.
  
### Sampling methods

- [Sequential Monte Carlo (PDF)](https://www.stats.ox.ac.uk/~doucet/doucet_defreitas_gordon_smcbookintro.pdf)
- [Particle Gibbs sampling (PDF)](https://www.stats.ox.ac.uk/~doucet/andrieu_doucet_holenstein_PMCMC.pdf)

### EP/ADF

- [x] [Expectation Propagation for approximate Bayesian inference](https://arxiv.org/abs/1301.2294). Also related [PhD thesis (PDF)](https://tminka.github.io/papers/ep/minka-thesis.pdf)
- For NNs:
  - [Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks](https://arxiv.org/abs/1502.05336)
  - [Expectation Propagation for Neural Networks with Sparsity-promoting Priors](https://arxiv.org/abs/1303.6938)
  
### Classic papers

- [A Unifying Review of Linear Gaussian Models (PDF)](http://mlg.eng.cam.ac.uk/zoubin/papers/lds.pdf)

## Rota

- 20 Sep: Artur. EP/ADF: Sections 3.1 and 3.2 in [Minka's thesis](https://tminka.github.io/papers/ep/minka-thesis.pdf)
- 27 Sep: James. [Expectation propagation as a way of life](https://arxiv.org/abs/1412.4869)
